{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> DS 3000 </h1> </center>\n",
    "<center> <h1> Homework Assignment 6</h1> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> Benjamin Kosiborod </h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do\n",
    "\n",
    "* Carefully read the description.\n",
    "* Make sure you execute your code for each question and compare the output to the sample output provided.\n",
    "* Refrain from using advanced Python capabilities that were not covered in class.\n",
    "* When in doubt, ASK! Post a question on the Blackboard discussion forum for this homework assignment.\n",
    "* Complete the assignment on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to submit\n",
    "* When you are done with the assignment, save it.\n",
    "* Download it as a Jupyter Notebook (DS3000_HW6.ipynb)\n",
    "* Upload your downloaded Notebook to Google Colab (https://colab.research.google.com/notebooks/)\n",
    "* Get a shareable link to your Notebook on Colab\n",
    "    * Go to Share near the top-right corner of the screen.\n",
    "    * Make sure you select Anyone with the Link Can View)\n",
    "    * Copy the link\n",
    "* Go to Blackboard\n",
    "* **Upload your Jupyter Notebook through the Blackboard assignment dropbox link.**\n",
    "* **Paste the link to you Colab Notebook in the Add Comments field.**\n",
    "* You can submit multiple attempts. The last attempt will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h2> Part 1 </h2> </center>\n",
    "\n",
    "In this assignment, you will work with another popular ML dataset bundled with sci-kit learn: Boston House Prices. You will apply various regression estimators to the dataset.\n",
    "\n",
    "In this part of the assignment, you will retrieve and prepare the dataset for regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 (2pts)\n",
    "Write a function that retrieves the Boston House Prices dataset from Sci-kit Learn's datasets module:\n",
    "    * https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
    "    \n",
    "Your function should return a dataframe containing the features and target variables from this dataset as shown below:\n",
    "    * Your dataframe should include 506 rows and 14 columns.\n",
    "\n",
    "Hint: Use the dataset's DESCR attribute to learn more about the dataset and its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def boston_dataset():\n",
    "    from sklearn.datasets import load_boston\n",
    "    boston = load_boston()  # Bunch object\n",
    "\n",
    "    df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "    df[\"Value\"] = boston.target\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  Value  \n",
       "0       15.3  396.90   4.98   24.0  \n",
       "1       17.8  396.90   9.14   21.6  \n",
       "2       17.8  392.83   4.03   34.7  \n",
       "3       18.7  394.63   2.94   33.4  \n",
       "4       18.7  396.90   5.33   36.2  \n",
       "..       ...     ...    ...    ...  \n",
       "501     21.0  391.99   9.67   22.4  \n",
       "502     21.0  396.90   9.08   20.6  \n",
       "503     21.0  396.90   5.64   23.9  \n",
       "504     21.0  393.45   6.48   22.0  \n",
       "505     21.0  396.90   7.88   11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = boston_dataset()\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (2pts)\n",
    "Write a function that extracts and returns a tuple of features and target variables from the boston_df dataframe above. Features are all columns from 0 to 12, and the target is the target column.\n",
    "    * The features variable should be a DataFrame object with 506 rows and 13 columns\n",
    "    * The target variable should be Series object with 506 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_target(df):\n",
    "    features = df.drop(\"Value\", axis=1)\n",
    "    target = df[\"Value\"]\n",
    "    \n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = features_and_target(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      24.0\n",
       "1      21.6\n",
       "2      34.7\n",
       "3      33.4\n",
       "4      36.2\n",
       "       ... \n",
       "501    22.4\n",
       "502    20.6\n",
       "503    23.9\n",
       "504    22.0\n",
       "505    11.9\n",
       "Name: Value, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Part 2 </h1></center>\n",
    "\n",
    "In this part, you will apply and evaluate multiple regression estimators (Linear Regression, Ridge, Lasso, kNN, and LinearSVR) to the Boston housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 (2pts)\n",
    "Write a function that splits the dataset into training and testing sets. The function should return the training and test splits as shown in the sample function call. Use random_state=3000 when splitting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_the_dataset():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    return train_test_split(features, target, random_state=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_the_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 (2pts)\n",
    "You will find it useful to define a dictionary containing these five regression estimators so you can apply them in an iteration statement. For this question, import the relevant methods from sci-kit learn and define the estimators dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "estimators = {\"Linear Regression\":LinearRegression(), \"Ridge\":Ridge(), \"Lasso\":Lasso(), \"k-Nearest Neighbor\":KNeighborsRegressor(), \"Support Vector Machine\":LinearSVR(max_iter=1000000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001), Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False), KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform'), LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000000,\n",
       "          random_state=None, tol=0.0001, verbose=0)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimators.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 (6pts)\n",
    "Write a function that fits these regression estimators to the training data using a percentage-split approach. You should use an iteration statement to apply these regression estimators. R-squared values should be displayed for both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressors_percentage_split():\n",
    "    from sklearn.metrics import r2_score\n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        estimator = estimator_object.fit(X=X_train, y=y_train)\n",
    "        r2_train = r2_score(y_train, estimator.predict(X_train))\n",
    "        r2_test = r2_score(y_test, estimator.predict(X_test))\n",
    "        print(estimator_name + \": \\n\\tR-squared value for training set: \", r2_train)\n",
    "        print(\"\\tR-squared value for testing set: \", r2_test, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "\tR-squared value for training set:  0.7323283273776776\n",
      "\tR-squared value for testing set:  0.7550324484990905 \n",
      "\n",
      "Ridge: \n",
      "\tR-squared value for training set:  0.7300063658794942\n",
      "\tR-squared value for testing set:  0.7527021619133469 \n",
      "\n",
      "Lasso: \n",
      "\tR-squared value for training set:  0.6698842056306404\n",
      "\tR-squared value for testing set:  0.7358166075709341 \n",
      "\n",
      "k-Nearest Neighbor: \n",
      "\tR-squared value for training set:  0.6905483702094808\n",
      "\tR-squared value for testing set:  0.5578500023483849 \n",
      "\n",
      "Support Vector Machine: \n",
      "\tR-squared value for training set:  0.6719077394333222\n",
      "\tR-squared value for testing set:  0.7328122386951904 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bendavp/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "regressors_percentage_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 (6pts)\n",
    "\n",
    "For this question, you will normalize the X_train and X_test variables and perform the same multiple model fitting/evaluation that you did in the previous question. The output of this question will be similar to that of the previous question, with only one major distinction: here the normalized variables will be used to train and test the algorithms. For normalization, apply **MinMaxScaler()**.\n",
    "\n",
    "Write a function that first applies the MinMaxScaler to the X_train and X_test global variables (as defined above) and then applies the same regression estimators. This function should also return the scaled variables, X_train_scaled and X_test_scaled respectively. You will need these variables in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_regression():\n",
    "    from sklearn.metrics import r2_score\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    #create the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    #fit the scaler to the training data(features only)\n",
    "    scaler.fit(X_train) \n",
    "\n",
    "    #transform X_train and X_test based on the (same) scaler\n",
    "    X_train_scaled = scaler.transform(X_train) \n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "    \n",
    "    #print the r-squared value for fitting to scaled data\n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        estimator = estimator_object.fit(X=X_train_scaled, y=y_train)\n",
    "        r2_train = r2_score(y_train, estimator.predict(X_train_scaled))\n",
    "        r2_test = r2_score(y_test, estimator.predict(X_test_scaled))\n",
    "        print(estimator_name + \": \\n\\tR-squared value for training set: \", r2_train)\n",
    "        print(\"\\tR-squared value for testing set: \", r2_test, \"\\n\")\n",
    "        \n",
    "    #return the scaled data\n",
    "    return (X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "\tR-squared value for training set:  0.7323283273776776\n",
      "\tR-squared value for testing set:  0.7550324484990883 \n",
      "\n",
      "Ridge: \n",
      "\tR-squared value for training set:  0.7280315503960804\n",
      "\tR-squared value for testing set:  0.7575337513870872 \n",
      "\n",
      "Lasso: \n",
      "\tR-squared value for training set:  0.24277577977555664\n",
      "\tR-squared value for testing set:  0.2761901820911663 \n",
      "\n",
      "k-Nearest Neighbor: \n",
      "\tR-squared value for training set:  0.8127102351677595\n",
      "\tR-squared value for testing set:  0.7726679668490197 \n",
      "\n",
      "Support Vector Machine: \n",
      "\tR-squared value for training set:  0.6072992749120545\n",
      "\tR-squared value for testing set:  0.6753980052100822 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = preprocessed_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7 (6pts)\n",
    "Looking at the previous output, it can be said that the kNN algorithm seems to works best for this dataset. In this question, you will attempt to improve the prediction performance by automatically selecting the most important features (k=3). \n",
    "\n",
    "Use recursive feature elimination (RFE) to select the three most important features. For your RFE, use a decition tree regressor to recursively eliminate the features. Your selection must be based on the X_train_scaled and X_test_scaled variables defined in the previous question. \n",
    "\n",
    "The idea is to use the scaled values that provided better results than raw values and to see if we can further improve the prediction performance by only using the most important features. Your function should produce the sample output given below and should also return the selected features, X_train_selected and X_test_selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFE_feature_selection():\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    #import and set feature selection algorithm RFE\n",
    "    select = RFE(DecisionTreeRegressor(random_state = 3000), n_features_to_select = 3)\n",
    "    \n",
    "    #fit the RFE selector to the scaled training data\n",
    "    select.fit(X_train_scaled, y_train)\n",
    "\n",
    "    #transform scaled training and testing sets so only the selected features are retained\n",
    "    X_train_selected = select.transform(X_train_scaled)\n",
    "    X_test_selected = select.transform(X_test_scaled)\n",
    "\n",
    "    # print the selected features\n",
    "    print(\"Selected features after RFE:\")\n",
    "    for feature, included in zip(features.columns.values, select.get_support()):\n",
    "        if included:\n",
    "            print(\"\\t\", feature)\n",
    "            \n",
    "    # get model and fit to selected features\n",
    "    model = estimators.get(\"k-Nearest Neighbor\").fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "    # print r2 scores\n",
    "    r2_train = r2_score(y_train, model.predict(X_train_selected))\n",
    "    r2_test = r2_score(y_test, model.predict(X_test_selected))\n",
    "    print(\"\\nkNN Regression performance with selected features:\")\n",
    "    print(\"\\tR-squared value for training set: \", r2_train)\n",
    "    print(\"\\tR-squared value for testing set: \", r2_test)\n",
    "    \n",
    "    #return selected features\n",
    "    return(X_train_selected, X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features after RFE:\n",
      "\t RM\n",
      "\t DIS\n",
      "\t LSTAT\n",
      "\n",
      "kNN Regression performance with selected features:\n",
      "\tR-squared value for training set:  0.8563961555616235\n",
      "\tR-squared value for testing set:  0.7769401779889553\n"
     ]
    }
   ],
   "source": [
    "X_train_selected, X_test_selected = RFE_feature_selection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8 (6pts)\n",
    "\n",
    "In this last question, you will perform a Grid Search to tune two key parameters of the kNN regression algorithm at the same time and determine which combination yields the best performance. Specifically, you will change the number of neighbors, n_neighbors, and the distance function used to calculate the distance between different data points, metric. For your convenience, these parameters and their values are provided below. \n",
    "\n",
    "\n",
    "Write a function that applies a Grid Search with kNN regression estimator and evaluates the performance of these parameters using 5-fold evaluation. Your function should produce the provided output. Your function should use the X_train_selected and X_test_selected variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_neighbors\":[1, 5, 10], \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_kNN():\n",
    "    \n",
    "    #import GridSearchCV and fit GridSearchCV\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    grid_search = GridSearchCV(estimators.get(\"k-Nearest Neighbor\"), param_grid, cv=5)\n",
    "\n",
    "    #fit the grid search object on the selected training data (CV will be performed on this)\n",
    "    grid_search.fit(X=X_train_selected, y=y_train)\n",
    "\n",
    "    #result of grid search\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    print(\"Training set score with the best parameters: \", grid_search.score(X_train_selected, y_train))\n",
    "\n",
    "    #the performance of the best found parameters on the test set\n",
    "    #this is what you report for the evaluation of your model\n",
    "    print(\"Test set score with best parameters: \", grid_search.score(X_test_selected, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'metric': 'manhattan', 'n_neighbors': 10}\n",
      "Training set score with the best parameters:  0.8246511818030201\n",
      "Test set score with best parameters:  0.7978997788865594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bendavp/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_search_kNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
